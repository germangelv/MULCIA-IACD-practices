{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZY3nLJO1SJY"
   },
   "source": [
    "## Inteligencia Artificial para la Ciencia de los Datos\n",
    "## Máster en Lógica, Computación e Inteligencia Artificial \n",
    "## Tema 2: Modelos probabilísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648140614696,
     "user": {
      "displayName": "Germán Lorenz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghcgaw9-t_7tmpdKWcVZ6gn5SNRLUilB4Mq8SydqA=s64",
      "userId": "17546947320916964948"
     },
     "user_tz": -60
    },
    "hide_input": false,
    "id": "xs0Qdu2Y1SJg"
   },
   "outputs": [],
   "source": [
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA5O1Xd91SJi"
   },
   "source": [
    "### Ejercicio 2: clasificación de textos usando Naive Bayes multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGPOn-ag1SJj"
   },
   "source": [
    "Este ejemplo está parcialmente tomado del libro:\n",
    "\n",
    "[*Introduction to Machine Learning with Python*](http://shop.oreilly.com/product/0636920030515.do)  \n",
    "**Andreas C. Müller & Sarah Guido**  \n",
    "O'Reilly 2017\n",
    "\n",
    "En concreto, este tema está basado en el capítulo 7, pero con modificaciones. \n",
    "\n",
    "Github con el material del libro: [Github](https://github.com/amueller/introduction_to_ml_with_python). \n",
    "\n",
    "El libro está accesible *online* desde la [Biblioteca de la Universidad de Sevilla](https://fama.us.es), como recurso electrónico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BjqXLXB1SJk"
   },
   "source": [
    "### Aplicación: análisis de sentimientos en textos\n",
    "\n",
    "Como datos en nuestar aplicación usaremos críiticas de películas en la web IMDB (Internet Movie Database). Son críticas que ya vienen con la etiqueta \"pos\" o \"neg\", de acuerdo a la puntuación que acompaña a la crítica (positiva, 7 o más; negativa 4 o menos). El objetivo es ser capaz de declarar como positiva o negativa una crítica (por supuesto, sin saber la puntuación que la acompaña).\n",
    "\n",
    "Los datos están disponibles en http://ai.stanford.edu/~amaas/data/sentiment/, pero usaremos un subconjunto de ellos que se puede obtener descomprimiendo el archivo `aclImdb.tar.gz`.\n",
    "\n",
    "Al descomprimir tendremos dos carpetas, test y train,en cada una de ellas con dos subcarpetas pos y neg, separando las críticas negativas y positivas, cada una en un archivo individual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wm4-EahV1SJl"
   },
   "source": [
    "#### Apartado 1\n",
    "La función `load_files` que viene en el módulo `datasets` de scikit-learn permite cargar conjuntos de datos que vienen en carpetas con esa estructura. Consultar en el manual para saber cómo usarla para cargar las críticas y sus valores de clasificación en cuatro variables:\n",
    "\n",
    "* `text_train` y `text_test` ambas listas de strings, y cada elelemnto de esas listas siendo el texto de una revisión. \n",
    "\n",
    "* `y_train` e `y_test` con los correspondientes valores de clasificación.\n",
    "\n",
    "\n",
    "**Nota**: los textos originales tienen muchas etiquetas de cambio de línea que es conveniente quitar. Esto se puede hacer fácilmente así:\n",
    "\n",
    "```python\n",
    "[doc.replace(b\"<br />\", b\" \") for doc in textos]\n",
    "```\n",
    "\n",
    "Explorar los datos brevemente: cuántos ejemplos hay, cuántos de cada clase, mostrar algunas críticas positivas y negativas,...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dbgfvu7K1SJm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['neg', 'pos']\n",
      "Número de ejemplos en test: 25000\n",
      "Ejemplos por cada clase: [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "# Solución:\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "reviews_train = load_files(\"aclImdb/train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "\n",
    "print(\"Clases: {}\".format(reviews_train.target_names))\n",
    "\n",
    "reviews_test = load_files(\"aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "print(\"Número de ejemplos en test: {}\".format(len(text_test)))\n",
    "print(\"Ejemplos por cada clase: {}\".format(np.bincount(y_test)))\n",
    "\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdiEqnF1SJn"
   },
   "source": [
    "### El modelo vectorial *Bag of Words*\n",
    "\n",
    "Antes de poder aplicar modelos de aprendizaje a textos, debemos representar los documentos mediante vectores numéricos. La forma más fácil de hacerlo es, una vez fijado los términos de nuestro *Vocabulario* (y un orden implícito entre los términos), mediante un vector en el que en cada componente tenemos el número de veces que aparece el correspondiente término del vocabulario, en el documento. Esto se puede hacer fácilmente en scikit learn con `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu5u3rlb1SJo"
   },
   "source": [
    "#### Apartado 2\n",
    "\n",
    "Para prácticar previamente con ejemplo sencillo, vamos a usar `CountVectorizer` para la vectorización de las siguientes cuatro frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ufaI1l7Q1SJp"
   },
   "outputs": [],
   "source": [
    "cuatro_frases =[\"Cargamento de oro dañado por el fuego\",\n",
    "              \"La entrega de la plata llegó en el camión color plata\",\n",
    "              \"El cargamento de oro llegó en un camión\",\n",
    "              \"Oro, oro, oro: gritó al ver el camión\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSmOBuFP1SJq"
   },
   "source": [
    "Se pide:\n",
    "\n",
    "* Vectorizar estas cuatro frases con `CountVectorizer` (ver detalles en el manual)\n",
    "* Consultar el vocabulario creado\n",
    "* Consultar los vectores creados, comprendiendo la representación\n",
    "\n",
    "*Nota*: puesto que en una representación vectorial de un texto la mayoría de las componentes son cero (todos los términos del vocabulario que no están en el documento), la representación más adecuada es mediante matrices dispersas de Scipy. El método `toarray` nos permite ver las matrices dispersas como arrays de numpy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bMDeGV5E1SJr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', 'camión', 'cargamento', 'color', 'dañado', 'de', 'el', 'en', 'entrega', 'fuego', 'gritó', 'la', 'llegó', 'oro', 'plata', 'por', 'un', 'ver']\n",
      "[[0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 1 1 1 1 0 0 2 1 0 2 0 0 0]\n",
      " [0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0]\n",
      " [1 1 0 0 0 0 1 0 0 0 1 0 0 3 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Solución\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(cuatro_frases)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())\n",
    "# De esta forma representmaos vectorialmente las frases por las repeticiones de las mismas\n",
    "# El peso de las palabras\n",
    "# Se convierte en un vector de caracteristicas\n",
    "\n",
    "vect2 = CountVectorizer(min_df=100, stop_words=\"english\").fit(text_train)\n",
    "X2_train = vect2.transform(text_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-2Kqhcz1SJs"
   },
   "source": [
    "#### Apartado 3\n",
    "\n",
    "Aplicar la vectorización a las críticas de cine, tanto las de entenamiento como las de test, almacenando los datos generados en variables `X_train` y `X_test`. Explorar también el vocabulario que se ha generado (tamaño, algunos términos, etc...)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UxIK0eAN1SJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solución:\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "\n",
    "vectorizer\n",
    "\n",
    "# en el entrenamiento obtendremos las probabilidades de cada palabra \n",
    "# despues deberemos sumarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario: 74849\n",
      "Primeras 20 características (términos):\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
      "Términos del 20010 al 20030:\n",
      "['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
      "Términos cada 2000 posiciones:\n",
      "['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario: {}\".format(len(feature_names)))\n",
    "print(\"Primeras 20 características (términos):\\n{}\".format(feature_names[:20]))\n",
    "print(\"Términos del 20010 al 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Términos cada 2000 posiciones:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6oI6Bps1SJt"
   },
   "source": [
    "#### Apartado 4\n",
    "\n",
    "Aplicar a los datos vectorizados el clasificador `MultinomialNB` para obtener predicciones sobre el \"sentimiento\" de una crítica. Mostrar varios ejemplos de predicciones sobre críticas, tanto del conjunto de entrenamiento como del conjunto de test. Mostrar también el rendimiento global sobre ambos conjuntos, probando también con distintos valores de la constante de suavizado. \n",
    "\n",
    "Examinar los atributos `class_count_`, `class_log_prior_`, `feature_count_` y `feature_log_prob_`, entendiendo qué contiene cada uno de ellos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[y_train==0][:,0].toarray()).sum()\n",
    "# ver uqe hace esta linea\n",
    "# obtiene el 51 de abajo osea las repeticiones de la frase \"0\" son 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o0Z9-gbI1SJt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12500. 12500.]\n",
      "[-0.69314718 -0.69314718]\n",
      "[[ 51. 174.   1. ...   0.   3.   1.]\n",
      " [ 42. 126.   0. ...   1.   1.   0.]]\n",
      "[[-10.90247427  -9.68893202 -14.16057081 ... -14.85371799 -13.46742363\n",
      "  -14.16057081]\n",
      " [-11.11979709 -10.03681011 -14.8809972  ... -14.18785002 -14.18785002\n",
      "  -14.8809972 ]]\n"
     ]
    }
   ],
   "source": [
    "# Solución\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Regresión logística con el parámetro por defecto\n",
    "multinb=MultinomialNB().fit(X_train,y_train)\n",
    "\n",
    "print(multinb.class_count_)\n",
    "\n",
    "print(multinb.class_log_prior_)\n",
    "\n",
    "print(multinb.feature_count_)\n",
    "\n",
    "print(multinb.feature_log_prob_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfJvdehH1SJu"
   },
   "source": [
    "#### Apartado 5\n",
    "\n",
    "Los *stop words* son palabras de uso tan frecuente que no aportan nada a la clasificación de textos (ya que no dan información sobre la clase a la que se pertenece). Igualmente, aquellos términos de muy baja frecuencia podrían ignorarse y así ganar en eficiencia (se tendrían menos características). Las opciones `min_df` y `stop_words` del vectorizador nos permiten llevar a cabo esto. \n",
    "\n",
    "Se pide vectorizar con ambas opciones (por ejemplo, `min_df=100` y `stop_words=english`), comprobar tamaño del vocabulario y los vectores generados, y el rendimiento del clasificador obtenido de nuevo con `MultinomialNB`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZtDF-JXh1SJu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segunda crítica del conjunto de test: \n",
      "\n",
      "b'I don\\'t know how this movie has received so many positive comments. One can call it \"artistic\" and \"beautifully filmed\", but those things don\\'t make up for the empty plot that was filled with sexual innuendos. I wish I had not wasted my time to watch this movie. Rather than being biographical, it was a poor excuse for promoting strange and lewd behavior. It was just another Hollywood attempt to convince us that that kind of life is normal and OK. From the very beginning I asked my self what was the point of this movie,and I continued watching, hoping that it would change and was quite disappointed that it continued in the same vein. I am so glad I did not spend the money to see this in a theater!'\n",
      "\n",
      "Clasificación verdadera: 0.\n",
      "\n",
      "\n",
      "Tercera crítica del conjunto de test: \n",
      "\n",
      "b\"I caught this movie on the Horror Channel and was quite impressed by the film's Gothic atmosphere and tone. As a big fan of all things vampire related, I am always happy to see a new variation of the vampire mythos, in this case, a ghoul-like creature residing in a Lovecraftian other dimension. The director has done a brilliant job of conveying the dark mood of the subject, using the decadent art scene as a backdrop to what is essentially a tale of love spanning time and space- the pure love of friendship opposed to the lust for blood and life by the vampires in the story. The characters in the story are transported to another dimension by the means of a mind-altering substance, where a shape-shifting vampire creature appears to grant them their hearts desires, whilst draining them of their life essence. There are some analogies to drug addiction and loss of control, and how this affects a group of friends in an artistic circle. I enjoyed watching the 2 main male characters in the story, Chris Ivan Cevic and Alex Petrovich, who were very attractive hunks, always a plus point in a vampire story for the female viewers! The special effects make up and creature effects were well done, and the set design of the vampire's dimension was very effective. All in all, an enjoyable take on vampire myths, and recommended for anyone who likes their vampires with some intelligence and not just action. The only thing missing to make it even better would have been a bit more eroticism and nudity, as it would have suited the plot and themes.\"\n",
      "\n",
      "Clasificación verdadera: 1\n"
     ]
    }
   ],
   "source": [
    "# Solución:\n",
    "print(\"Segunda crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[1]))\n",
    "print(\"Clasificación verdadera: {}.\\n\\n\".format(y_test[1]))\n",
    "print(\"Tercera crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[2]))\n",
    "print(\"Clasificación verdadera: {}\".format(y_test[2]))\n",
    "# Sabemos loq ue vale cada critica porque lo tenemos\n",
    "# ahora veremos con predict que tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción del clasificador para la segunda crítica: 0\n",
      "\n",
      "Predicción del clasificador para la tercera crítica: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción del clasificador para la segunda crítica: {}\\n\".format(multinb.predict(vect.transform([text_test[1]]))[0]))\n",
    "print(\"Predicción del clasificador para la tercera crítica: {}\".format(multinb.predict(vect.transform([text_test[2]]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción de probabilidad para la segunda crítica: [9.99999862e-01 1.37575474e-07]\n",
      "\n",
      "Predicción de probabilidad para la tercera crítica: [0.01977596 0.98022404]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción de probabilidad para la segunda crítica: {}\\n\".format(multinb.predict_proba(vect.transform([text_test[1]]))[0]))\n",
    "print(\"Predicción de probabilidad para la tercera crítica: {}\".format(multinb.predict_proba(vect.transform([text_test[2]]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera crítica del conjunto de test: \n",
      "\n",
      "b\"Don't hate Heather Graham because she's beautiful, hate her because she's fun to watch in this movie. Like the hip clothing and funky surroundings, the actors in this flick work well together. Casey Affleck is hysterical and Heather Graham literally lights up the screen. The minor characters - Goran Visnjic {sigh} and Patricia Velazquez are as TALENTED as they are gorgeous. Congratulations Miramax & Director Lisa Krueger!\"\n",
      "\n",
      "Clasificación verdadera: 1.\n",
      "\n",
      "Predicción del clasificador para la primera crítica: 0\n",
      "\n",
      "Predicción de probabilidad para la primera crítica: [0.68716538 0.31283462]\n"
     ]
    }
   ],
   "source": [
    "print(\"Primera crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[0]))\n",
    "print(\"Clasificación verdadera: {}.\\n\".format(y_test[0]))\n",
    "print(\"Predicción del clasificador para la primera crítica: {}\\n\".format(multinb.predict(vect.transform([text_test[0]]))[0]))\n",
    "print(\"Predicción de probabilidad para la primera crítica: {}\".format(multinb.predict_proba(vect.transform([text_test[0]]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb sobre el conjunto de entrenamiento: 0.90\n",
      "Rendimiento de multinb sobre el conjunto de test: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Rendimiento de multinb sobre el conjunto de entrenamiento: {:.2f}\".format(multinb.score(X_train,y_train)))\n",
    "print(\"Rendimiento de multinb sobre el conjunto de test: {:.2f}\".format(multinb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario original: 74849\n",
      "Número de términos en el vocabulario con stop words y min_df: 3561\n"
     ]
    }
   ],
   "source": [
    "# Mejorando el entrenamiento con los cambios de features y reduccion de palabras se obtiene las siguiente celdas interesantes\n",
    "# Hay que saberlas explicar !!!\n",
    "print(\"Número de términos en el vocabulario original: {}\".format(len(feature_names)))\n",
    "feature_names2 = vect2.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df: {}\".format(len(feature_names2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinb2=MultinomialNB(alpha=1).fit(X2_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb2 sobre el conjunto de entrenamiento 0.86\n",
      "Rendimiento de multinb2 sobre el conjunto de test: 0.84\n"
     ]
    }
   ],
   "source": [
    "X2_test = vect2.transform(text_test)\n",
    "print(\"Rendimiento de multinb2 sobre el conjunto de entrenamiento {:.2f}\".format(multinb2.score(X2_train,y_train)))\n",
    "print(\"Rendimiento de multinb2 sobre el conjunto de test: {:.2f}\".format(multinb2.score(X2_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "ejercicio-2-iacd-modelos-prob.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
