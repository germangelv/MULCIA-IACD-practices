{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826d06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "\n",
    "    def __init__(self,k=1):        \n",
    "        self.k = k\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.uniqueClas = None\n",
    "        self.p_c = []\n",
    "        self.list_p_condics = []\n",
    "        self.probabilidades_c = {}\n",
    "        self.flag_entrenado = False\n",
    "        \n",
    "    def entrena(self,X,y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "        #countsClas nos da el nº de veces se da un valor de clasificación, uniqueClas los dos posibles valores de \n",
    "        #clasificación ('si' y 'no')\n",
    "        uniqueClas, countsClas = np.unique(y, return_counts=True)\n",
    "        self.uniqueClas = uniqueClas\n",
    "    \n",
    "        #Función de probabilidad P(C=c)\n",
    "        p_c = []\n",
    "        for i in range(len(uniqueClas)):\n",
    "            p_c.append(countsClas[i]/len(y))\n",
    "            \n",
    "        self.p_c = p_c\n",
    "        \n",
    "        #Listado de probabilidades condicionales\n",
    "        list_p_condics = []\n",
    "        self.list_p_condics = list_p_condics\n",
    "        \n",
    "        for i in list(uniqueClas): #Por cada valor de clasificación ('si' o 'no'), vamos a añadir un registro en list_p_condics\n",
    "            p_condics =[] #Matriz para el valor de clasificación i\n",
    "            \n",
    "            for j in range(X.shape[1]): #Por cada atributo, vamos a calcular sus probabilidades condicionadas. \n",
    "                                        #j es el nº de atributo \n",
    "        \n",
    "                valuesAtribj, numberOfValuesAtribj = np.unique(X[:,j], return_counts=True)\n",
    "                p_condics_j = [] #Por cada atributo, tenemos la fila de las probabilidades condicionadas\n",
    "                \n",
    "                for k in range(len(valuesAtribj)): #Por cada valor que puede tomar el atributo,\n",
    "                                                   #vamos a calcular su probabilidad condicionada\n",
    "                    \n",
    "                    positionsOfk = np.where(X[:,j] == valuesAtribj[k]) #Posiciones en las que el atributo j vale k\n",
    "                    #Formamos el vector y con las posiciones en las que el clasificador vale i y el atributo j vale k\n",
    "                    y_k = []\n",
    "                    for l in positionsOfk: #Por cada valor de posición de k, nos quedamos con las posiciones de y, formamos y_k\n",
    "                        y_k.append(y[l])\n",
    "                        \n",
    "                    positionsOfk_i = np.where(y_k[0] == i) #Posiciones del valor de clasificación i en y\n",
    "                    y_ki = []\n",
    "                    for m in positionsOfk_i:\n",
    "                        y_ki.append(y_k[0][m])\n",
    "                        \n",
    "                    #Nº de ejemplos clasificados como i en el atributo j con valor k    \n",
    "                    n_i_j_k = len(y_ki[0])\n",
    "                    \n",
    "                    p_condics_j.append((n_i_j_k + self.k)/(countsClas[np.where(uniqueClas == i)][0] + self.k*len(valuesAtribj)))\n",
    "                    \n",
    "                p_condics.append(p_condics_j)\n",
    "            \n",
    "            list_p_condics.append(p_condics)\n",
    "            self.flag_entrenado = True\n",
    "\n",
    "    def clasifica_prob(self,ejemplo):\n",
    "        if (self.flag_entrenado == False):\n",
    "            raise ClasificadorNoEntrenado(\"Debe entrenar antes el clasificador.\")\n",
    "        else:\n",
    "                \n",
    "            #Por cada atributo de 'ejemplo', buscamos sus dos probabilidades condicionadas en la matriz construida\n",
    "            probabilidades_c = {}\n",
    "            \n",
    "            for c in list(self.uniqueClas):\n",
    "                posic_c = np.where(self.uniqueClas == c)[0][0]\n",
    "                \n",
    "                probs_condics = []\n",
    "                \n",
    "                for a in range(len(ejemplo)): #Por cada valor de los atributos, sacamos su probabilidad condicionada de la matriz construida\n",
    "                    matriz_p_c = self.list_p_condics[posic_c] #Matriz para el valor de clasificación actual\n",
    "                    valuesAtriba, numberOfValuesAtriba = np.unique(self.X[:,a], return_counts=True)\n",
    "                    fila = a #Corresponde al nº de atributo\n",
    "                    columna = np.where(valuesAtriba == ejemplo[a])[0][0] #Corresponde al valor del atributo\n",
    "                    probs_condics.append(matriz_p_c[fila][columna])\n",
    "                \n",
    "                sum_logs = np.sum([math.log(x,10) for x in probs_condics])\n",
    "                resultado = math.log(self.p_c[posic_c],10) + sum_logs\n",
    "                probabilidades_c[c] = (resultado)\n",
    "                probs_condics = []\n",
    "                \n",
    "            self.probabilidades_c = probabilidades_c\n",
    "            return probabilidades_c\n",
    "\n",
    "    def clasifica(self,ejemplo):\n",
    "        if (self.flag_entrenado == False):\n",
    "            raise ClasificadorNoEntrenado(\"Debe entrenar antes el clasificador.\")\n",
    "        else:\n",
    "            maximo = {}\n",
    "            find_max = max(self.clasifica_prob(ejemplo), key=self.clasifica_prob(ejemplo).get)\n",
    "            maximo[find_max] = self.clasifica_prob(ejemplo)[find_max]\n",
    "        \n",
    "        return maximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ac65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rendimiento_p1(clasificador,X,y):\n",
    "    y_prediccion = []\n",
    "    for x in X:\n",
    "        y_prediccion.append([k for k, v in clasificador.clasifica(x).items()][0])\n",
    "    total=len(y)\n",
    "    v_ok=[]\n",
    "    for i in range(len(y)):\n",
    "        if y[i]==y_prediccion[i]:\n",
    "            v_ok.append(i)\n",
    "    return len(v_ok)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6ab37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run \"votos.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab14685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b49404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_votos_train, X_votos_test, y_votos_train, y_votos_test = train_test_split(datos, clasif, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0794dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8899082568807339"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_votos = NaiveBayes(k=0.5)\n",
    "nb_votos.entrena(X_votos_train,y_votos_train)\n",
    "rendimiento_votos=rendimiento_p1(nb_votos,X_votos_test,y_votos_test)\n",
    "rendimiento_votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d95575be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.902449346506935"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = nb_votos.clasifica(X_votos_test[0]).get(1)\n",
    "prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd10cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit    \n",
    "\n",
    "\n",
    "def suma_paralelo(a1, a2):\n",
    "    \"\"\"\n",
    "        Recibe dos arrays y devuelve un array con las sumas de sus componentes sumadas\n",
    "    \"\"\"\n",
    "    a3 = [a1[i]+a2[i] for i in range(len(a1))]\n",
    "    return a3\n",
    "\n",
    "\n",
    "def sigmoide(x):\n",
    "    return expit(x)\n",
    "\n",
    "\n",
    "def normaliza(X):\n",
    "    \"\"\"Normaliza los datos\"\"\"\n",
    "    medias = np.mean(X, axis=0)\n",
    "    desvs = np.std(X, axis=0)\n",
    "    X_norm = (X - medias) / desvs\n",
    "    return X_norm\n",
    "\n",
    "\n",
    "class RegresionLogisticaMiniBatch():\n",
    "\n",
    "    def __init__(self, clases=[0, 1], normalizacion=False,\n",
    "                rate=0.1, rate_decay=False, batch_tam=64, n_epochs=200,\n",
    "                 pesos_iniciales=None):\n",
    "        \n",
    "        mapa_reverse = {0: clases[0], 1: clases[1]}\n",
    "        self.clases = clases\n",
    "        self.mapa_reverse = mapa_reverse\n",
    "        self.normalizacion = normalizacion\n",
    "        self.rate = rate\n",
    "        self.rate_decay = rate_decay\n",
    "        self.batch_tam = batch_tam\n",
    "        self.n_epochs = n_epochs\n",
    "        self.pesos_iniciales = pesos_iniciales\n",
    "        self.pesos = list()\n",
    "        # si pesos está vacía, el clasificador no está entrenado\n",
    "        self.flag_entrenado = False\n",
    "\n",
    "\n",
    "\n",
    "    def entrena(self, X, y):\n",
    "        \n",
    "        pesos = []\n",
    "        if self.pesos_iniciales is not None:  # tomamos los pesos directamente de la clase\n",
    "            pesos = list(self.pesos_iniciales)\n",
    "        else:  # iniciamos los pesos de forma aleatoria\n",
    "            pesos = [random.random() for i in range(X.shape[1])]\n",
    "        n_epochs = self.n_epochs\n",
    "        y_2 = y.reshape(len(y), 1) #transformamos y para poder luego unirlo a X\n",
    "\n",
    "        if self.normalizacion:\n",
    "            X = normaliza(X)\n",
    "                    \n",
    "        # merge de los array para trabajar mejor con ellos\n",
    "        big_chunk = np.concatenate((X, y_2), axis=1)\n",
    "        # inicialización de parámetros\n",
    "        batch_tam = self.batch_tam\n",
    "        tasa_l = self.rate\n",
    "        tasa_l0 = self.rate\n",
    "        for i in range(n_epochs):\n",
    "            chunks = np.array_split(big_chunk, batch_tam)\n",
    "            # dividimos los datos en subconjuntos\n",
    "            for block in chunks: #iteramos por cada minibatch\n",
    "                # tomamos un subgrupo de datos\n",
    "                # para cada subconjunto actualizamos\n",
    "                pesos_previos = [0.0 for _ in block[0][:-1]]\n",
    "                for array in block: #iteramos por cada ejemplo de nuestro minibatch para actualizar los pesos\n",
    "                    sum_a = array[-1]-sigmoide(np.dot(pesos, array[:-1]))\n",
    "                    sum_t = np.dot(sum_a, array[:-1])\n",
    "                    pesos_previos = suma_paralelo(pesos_previos, sum_t)\n",
    "                # una vez hecho todo el sumatorio de los elementos del subgrupo,\n",
    "                # actualizamos los pesos reales multiplicando por la tasa de\n",
    "                # aprendizaje y sumando\n",
    "                \n",
    "                act_b = np.dot(tasa_l, pesos_previos)\n",
    "                pesos = suma_paralelo(pesos, act_b)\n",
    "            if self.rate_decay:\n",
    "                tasa_l = tasa_l0*(1/(1+i))\n",
    "        self.pesos = pesos\n",
    "        self.flag_entrenado = True\n",
    "\n",
    "    def clasifica_prob(self, ejemplo):\n",
    "        if self.flag_entrenado == False:\n",
    "            raise ClasificadorNoEntrenado(\"Debe entrenar antes el clasificador.\")\n",
    "        else:\n",
    "            result = sigmoide(np.dot(self.pesos, ejemplo))\n",
    "            probs = dict()\n",
    "            reverse= self.mapa_reverse\n",
    "            probs[reverse.get(0)]=1-result\n",
    "            probs[reverse.get(1)]=result\n",
    "            return probs\n",
    "\n",
    "    def clasifica(self, ejemplo):\n",
    "        if self.flag_entrenado == False:\n",
    "            raise ClasificadorNoEntrenado(\"Debe entrenar antes el clasificador.\")\n",
    "        else:\n",
    "            #result = sigmoide(np.dot(self.pesos, ejemplo))\n",
    "            #return self.mapa_reverse.get(round(result))\n",
    "            maximo = {}\n",
    "            find_max = max(self.clasifica_prob(ejemplo), key=self.clasifica_prob(ejemplo).get)\n",
    "            maximo[find_max] = self.clasifica_prob(ejemplo)[find_max]\n",
    "            \n",
    "        return maximo\n",
    "\n",
    "\n",
    "\n",
    "def rendimiento_p2(clasificador, X, y):\n",
    "    \"\"\"\n",
    "    Devuelve el porcentaje de ejemplos bien clasificados\n",
    "    :param clasificador: clasificador a emplear\n",
    "    :param X: conjunto de ejemplos X\n",
    "    :param y: clasificacion esperada\n",
    "    \"\"\"\n",
    "    pred = []  # tablero que contenga nuestra prediccion para todos los ejemplos en X con el clasificador dado en argumento\n",
    "    for i in range(len(X)):\n",
    "        pred.append(clasificador.clasifica(X[i]))\n",
    "    return len(np.where(pred == y)[0]) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4440d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendimiento_p2(nb_votos,X_votos_test,y_votos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1976c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "193437fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_votos = RegresionLogisticaMiniBatch(rate=0.1,rate_decay=True,normalizacion=True)\n",
    "lr_votos.entrena(X_votos_train, y_votos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb732eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944954128440367"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendimiento_p1(lr_votos, normaliza(X_votos_test), y_votos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5dcc537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendimiento_p2(lr_votos, normaliza(X_votos_test), y_votos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cee79a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9477529359854218}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_votos.clasifica(normaliza(X_votos_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df13581d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -4.902449346506935}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_votos.clasifica(X_votos_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
